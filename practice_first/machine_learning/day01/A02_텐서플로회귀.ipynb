{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 사전준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기본 패키지 import\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 한글 설정/차트 마이너스 깨짐현상 해결 / seaborn 화면설정\n",
    "from matplotlib import rc\n",
    "import matplotlib.font_manager as fm\n",
    "\n",
    "plt.rc('font', family='Malgun Gothic')\n",
    "sns.set(font='Malgun Gothic', rc={'axes.unicode_minus':False}, style='darkgrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 머신러닝 패키지 import\n",
    "import statsmodels.api as sm # 안쓸껄??\n",
    "import sklearn as sk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 텐서플로 회귀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Sequential    # 모델박스를 위한, inputLayer, outputLayer를 포함할...\n",
    "from keras.layers import Flatten, Dense # Flatten은 inputLayer, Dense는 outputLayer\n",
    "\n",
    "# MSE로 도출, gradient desent 계열을 통해서 w와 b로 구함\n",
    "from keras.optimizers import SGD # GD를 개량한 Stock Gradient Desent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "perch_length = np.array(\n",
    "    [8.4, 13.7, 15.0, 16.2, 17.4, 18.0, 18.7, 19.0, 19.6, 20.0, \n",
    "     21.0, 21.0, 21.0, 21.3, 22.0, 22.0, 22.0, 22.0, 22.0, 22.5, \n",
    "     22.5, 22.7, 23.0, 23.5, 24.0, 24.0, 24.6, 25.0, 25.6, 26.5, \n",
    "     27.3, 27.5, 27.5, 27.5, 28.0, 28.7, 30.0, 32.8, 34.5, 35.0, \n",
    "     36.5, 36.0, 37.0, 37.0, 39.0, 39.0, 39.0, 40.0, 40.0, 40.0, \n",
    "     40.0, 42.0, 43.0, 43.0, 43.5, 44.0]\n",
    "     )\n",
    "perch_weight = np.array(\n",
    "    [5.9, 32.0, 40.0, 51.5, 70.0, 100.0, 78.0, 80.0, 85.0, 85.0, \n",
    "     110.0, 115.0, 125.0, 130.0, 120.0, 120.0, 130.0, 135.0, 110.0, \n",
    "     130.0, 150.0, 145.0, 150.0, 170.0, 225.0, 145.0, 188.0, 180.0, \n",
    "     197.0, 218.0, 300.0, 260.0, 265.0, 250.0, 250.0, 300.0, 320.0, \n",
    "     514.0, 556.0, 840.0, 685.0, 700.0, 700.0, 690.0, 900.0, 650.0, \n",
    "     820.0, 850.0, 900.0, 1015.0, 820.0, 1100.0, 1000.0, 1100.0, \n",
    "     1000.0, 1000.0]\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 훈련 세트와 테스트 세트로 나눕니다\n",
    "train_input, test_input, train_target, test_target = train_test_split(\n",
    "    perch_length, perch_weight, random_state=42)\n",
    "# 훈련 세트와 테스트 세트를 2차원 배열로 바꿉니다\n",
    "train_input = train_input.reshape(-1, 1)\n",
    "test_input = test_input.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 생성(구현)\n",
    "model = Sequential()  \n",
    "\n",
    "# inputLayer\n",
    "model.add(Flatten(input_shape=(1,))) # 독립계수 갯수 정의\n",
    "\n",
    "# outputLayer\n",
    "model.add(Dense(units=1,                # 출력레이어 결과 갯수 정의\n",
    "                activation='linear'))   # 아웃풋에서 아무것도 안하고 그냥 넘어가므로 \n",
    "# 모델 설정\n",
    "model.compile(optimizer=SGD(learning_rate=1e-4),    # learing rate 입력 / 최적인 learning rate는 모름(경험적으로 알아내야 함)\n",
    "              loss='mse')                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 50383.0430\n",
      "Epoch 2/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 50249.5938\n",
      "Epoch 3/300\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 50473.3281\n",
      "Epoch 4/300\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 50390.8281\n",
      "Epoch 5/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 50539.5781\n",
      "Epoch 6/300\n",
      "2/2 [==============================] - 0s 999us/step - loss: 50580.0000\n",
      "Epoch 7/300\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 50608.8984\n",
      "Epoch 8/300\n",
      "2/2 [==============================] - 0s 1000us/step - loss: 50510.7188\n",
      "Epoch 9/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 50325.0898\n",
      "Epoch 10/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 50177.2422\n",
      "Epoch 11/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 50313.9531\n",
      "Epoch 12/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 50525.1016\n",
      "Epoch 13/300\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 50215.5703\n",
      "Epoch 14/300\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 50252.1562\n",
      "Epoch 15/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 51412.1914\n",
      "Epoch 16/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 50586.0586\n",
      "Epoch 17/300\n",
      "2/2 [==============================] - 0s 144ms/step - loss: 50312.0781\n",
      "Epoch 18/300\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 50614.6602\n",
      "Epoch 19/300\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 50406.0586\n",
      "Epoch 20/300\n",
      "2/2 [==============================] - 0s 1000us/step - loss: 50278.5078\n",
      "Epoch 21/300\n",
      "2/2 [==============================] - 0s 1000us/step - loss: 50466.5234\n",
      "Epoch 22/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 50266.2422\n",
      "Epoch 23/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 50165.1016\n",
      "Epoch 24/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 50189.8867\n",
      "Epoch 25/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 50640.5234\n",
      "Epoch 26/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 50716.2617\n",
      "Epoch 27/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 50589.4336\n",
      "Epoch 28/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 50360.1562\n",
      "Epoch 29/300\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 50306.3320\n",
      "Epoch 30/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 50362.2734\n",
      "Epoch 31/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 50076.8672\n",
      "Epoch 32/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 50127.0078\n",
      "Epoch 33/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 50111.8438\n",
      "Epoch 34/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 50156.3945\n",
      "Epoch 35/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 50258.3828\n",
      "Epoch 36/300\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 50083.1562\n",
      "Epoch 37/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 51209.2148\n",
      "Epoch 38/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 50619.4297\n",
      "Epoch 39/300\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 50282.7031\n",
      "Epoch 40/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 50194.2852\n",
      "Epoch 41/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 50121.6055\n",
      "Epoch 42/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 50104.9922\n",
      "Epoch 43/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 50190.9062\n",
      "Epoch 44/300\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 50120.9219\n",
      "Epoch 45/300\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 50051.8555\n",
      "Epoch 46/300\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 50143.2305\n",
      "Epoch 47/300\n",
      "2/2 [==============================] - 0s 1000us/step - loss: 50131.6367\n",
      "Epoch 48/300\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 50094.7070\n",
      "Epoch 49/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 50026.3750\n",
      "Epoch 50/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 50695.6328\n",
      "Epoch 51/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 50675.8438\n",
      "Epoch 52/300\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 50585.0703\n",
      "Epoch 53/300\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 50571.2422\n",
      "Epoch 54/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 50487.8398\n",
      "Epoch 55/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 50098.5664\n",
      "Epoch 56/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 50015.8750\n",
      "Epoch 57/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 50018.1914\n",
      "Epoch 58/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 50002.2969\n",
      "Epoch 59/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 50188.6445\n",
      "Epoch 60/300\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 50120.8672\n",
      "Epoch 61/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 50072.3672\n",
      "Epoch 62/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 49987.3203\n",
      "Epoch 63/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 49981.6562\n",
      "Epoch 64/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 50432.1602\n",
      "Epoch 65/300\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 50296.8750\n",
      "Epoch 66/300\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 50284.2031\n",
      "Epoch 67/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 50327.8867\n",
      "Epoch 68/300\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 50246.1797\n",
      "Epoch 69/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 50004.0820\n",
      "Epoch 70/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 50009.1133\n",
      "Epoch 71/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 49977.5547\n",
      "Epoch 72/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 49957.6914\n",
      "Epoch 73/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 49997.9414\n",
      "Epoch 74/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 50121.1719\n",
      "Epoch 75/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 50651.1484\n",
      "Epoch 76/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 50089.3867\n",
      "Epoch 77/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 50097.2852\n",
      "Epoch 78/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 49964.7266\n",
      "Epoch 79/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 49979.9922\n",
      "Epoch 80/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 50371.3438\n",
      "Epoch 81/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 50289.2031\n",
      "Epoch 82/300\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 50149.9883\n",
      "Epoch 83/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 49969.9414\n",
      "Epoch 84/300\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 50329.2148\n",
      "Epoch 85/300\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 50283.4297\n",
      "Epoch 86/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 50353.1016\n",
      "Epoch 87/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 50258.0703\n",
      "Epoch 88/300\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 50072.4805\n",
      "Epoch 89/300\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 50054.0430\n",
      "Epoch 90/300\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 50041.0781\n",
      "Epoch 91/300\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 49983.6914\n",
      "Epoch 92/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 49894.9688\n",
      "Epoch 93/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 50074.8633\n",
      "Epoch 94/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 50263.5352\n",
      "Epoch 95/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 50248.9219\n",
      "Epoch 96/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 50624.4648\n",
      "Epoch 97/300\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 50810.1914\n",
      "Epoch 98/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 50684.4297\n",
      "Epoch 99/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 50099.3281\n",
      "Epoch 100/300\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 50024.1445\n",
      "Epoch 101/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 49960.1680\n",
      "Epoch 102/300\n",
      "2/2 [==============================] - 0s 1000us/step - loss: 50067.1797\n",
      "Epoch 103/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 50773.9531\n",
      "Epoch 104/300\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 50659.4336\n",
      "Epoch 105/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 50017.8203\n",
      "Epoch 106/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 50082.6133\n",
      "Epoch 107/300\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 50131.4648\n",
      "Epoch 108/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 50234.5117\n",
      "Epoch 109/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 49851.9141\n",
      "Epoch 110/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 49925.4453\n",
      "Epoch 111/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 49938.4180\n",
      "Epoch 112/300\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 50209.4531\n",
      "Epoch 113/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 50882.3945\n",
      "Epoch 114/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 50680.4414\n",
      "Epoch 115/300\n",
      "2/2 [==============================] - 0s 1000us/step - loss: 50055.1445\n",
      "Epoch 116/300\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 49979.8945\n",
      "Epoch 117/300\n",
      "2/2 [==============================] - 0s 999us/step - loss: 49874.4062\n",
      "Epoch 118/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 49875.1367\n",
      "Epoch 119/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 49828.6055\n",
      "Epoch 120/300\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 49817.1562\n",
      "Epoch 121/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 50003.8672\n",
      "Epoch 122/300\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 49926.4102\n",
      "Epoch 123/300\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 49945.7422\n",
      "Epoch 124/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 49893.2695\n",
      "Epoch 125/300\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 50210.0430\n",
      "Epoch 126/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 49955.8555\n",
      "Epoch 127/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 50435.1914\n",
      "Epoch 128/300\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 50296.4648\n",
      "Epoch 129/300\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 50051.6172\n",
      "Epoch 130/300\n",
      "2/2 [==============================] - 0s 1000us/step - loss: 49909.1914\n",
      "Epoch 131/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 49932.5352\n",
      "Epoch 132/300\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 50284.7969\n",
      "Epoch 133/300\n",
      "2/2 [==============================] - 0s 999us/step - loss: 50236.9180\n",
      "Epoch 134/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 50117.3047\n",
      "Epoch 135/300\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 50484.0117\n",
      "Epoch 136/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 50737.0352\n",
      "Epoch 137/300\n",
      "2/2 [==============================] - 0s 1000us/step - loss: 50508.4922\n",
      "Epoch 138/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 49962.3164\n",
      "Epoch 139/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 49947.9297\n",
      "Epoch 140/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 50163.8438\n",
      "Epoch 141/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 49813.2031\n",
      "Epoch 142/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 49756.3828\n",
      "Epoch 143/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 49752.7695\n",
      "Epoch 144/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 50085.2969\n",
      "Epoch 145/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 50033.7617\n",
      "Epoch 146/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 49965.2070\n",
      "Epoch 147/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 49873.7500\n",
      "Epoch 148/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 49853.3516\n",
      "Epoch 149/300\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 50143.6367\n",
      "Epoch 150/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 50208.1055\n",
      "Epoch 151/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 50139.8516\n",
      "Epoch 152/300\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 49789.4062\n",
      "Epoch 153/300\n",
      "2/2 [==============================] - 0s 1000us/step - loss: 49922.8320\n",
      "Epoch 154/300\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 49751.6953\n",
      "Epoch 155/300\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 49732.0938\n",
      "Epoch 156/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 49814.3242\n",
      "Epoch 157/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 50475.7734\n",
      "Epoch 158/300\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 51065.3633\n",
      "Epoch 159/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 51221.5195\n",
      "Epoch 160/300\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 51439.6602\n",
      "Epoch 161/300\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 51409.6836\n",
      "Epoch 162/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 51362.7734\n",
      "Epoch 163/300\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 51064.4648\n",
      "Epoch 164/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 50587.3867\n",
      "Epoch 165/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 49780.6406\n",
      "Epoch 166/300\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 49682.8398\n",
      "Epoch 167/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 49745.6172\n",
      "Epoch 168/300\n",
      "2/2 [==============================] - 0s 1000us/step - loss: 49839.9219\n",
      "Epoch 169/300\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 49889.5391\n",
      "Epoch 170/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 49685.0547\n",
      "Epoch 171/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 49689.5195\n",
      "Epoch 172/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 49689.0938\n",
      "Epoch 173/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 49701.5273\n",
      "Epoch 174/300\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 50051.5195\n",
      "Epoch 175/300\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 49787.7227\n",
      "Epoch 176/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 49866.1172\n",
      "Epoch 177/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 49855.2422\n",
      "Epoch 178/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 49850.9883\n",
      "Epoch 179/300\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 49674.9180\n",
      "Epoch 180/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 49661.7148\n",
      "Epoch 181/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 49653.7500\n",
      "Epoch 182/300\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 49693.5117\n",
      "Epoch 183/300\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 49699.2188\n",
      "Epoch 184/300\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 49761.2148\n",
      "Epoch 185/300\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 49771.6680\n",
      "Epoch 186/300\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 49878.7969\n",
      "Epoch 187/300\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 49653.9805\n",
      "Epoch 188/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 50148.7383\n",
      "Epoch 189/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 50359.9414\n",
      "Epoch 190/300\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 50226.2930\n",
      "Epoch 191/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 49739.8633\n",
      "Epoch 192/300\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 49805.5938\n",
      "Epoch 193/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 49661.7969\n",
      "Epoch 194/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 49692.5195\n",
      "Epoch 195/300\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 49815.3438\n",
      "Epoch 196/300\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 50306.3867\n",
      "Epoch 197/300\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 50262.0078\n",
      "Epoch 198/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 49958.3750\n",
      "Epoch 199/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 49746.6445\n",
      "Epoch 200/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 49715.0234\n",
      "Epoch 201/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 49608.7461\n",
      "Epoch 202/300\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 49578.8320\n",
      "Epoch 203/300\n",
      "2/2 [==============================] - 0s 1000us/step - loss: 49584.2578\n",
      "Epoch 204/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 49579.5430\n",
      "Epoch 205/300\n",
      "2/2 [==============================] - 0s 999us/step - loss: 49567.4102\n",
      "Epoch 206/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 49610.3008\n",
      "Epoch 207/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 49591.3750\n",
      "Epoch 208/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 49779.2031\n",
      "Epoch 209/300\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 49929.0547\n",
      "Epoch 210/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 49999.9414\n",
      "Epoch 211/300\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 49926.2500\n",
      "Epoch 212/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 49799.6914\n",
      "Epoch 213/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 49617.9805\n",
      "Epoch 214/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 49853.2305\n",
      "Epoch 215/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 49988.1914\n",
      "Epoch 216/300\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 50004.5352\n",
      "Epoch 217/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 49886.6484\n",
      "Epoch 218/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 49949.6914\n",
      "Epoch 219/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 50076.7930\n",
      "Epoch 220/300\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 50298.4883\n",
      "Epoch 221/300\n",
      "2/2 [==============================] - 0s 1000us/step - loss: 50568.3516\n",
      "Epoch 222/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 50385.1016\n",
      "Epoch 223/300\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 49975.3867\n",
      "Epoch 224/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 49927.6523\n",
      "Epoch 225/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 50052.8672\n",
      "Epoch 226/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 49513.8516\n",
      "Epoch 227/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 49611.8242\n",
      "Epoch 228/300\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 49873.8750\n",
      "Epoch 229/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 49581.5430\n",
      "Epoch 230/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 49588.3828\n",
      "Epoch 231/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 49736.1328\n",
      "Epoch 232/300\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 50120.1016\n",
      "Epoch 233/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 49958.5586\n",
      "Epoch 234/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 49726.5586\n",
      "Epoch 235/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 49491.8984\n",
      "Epoch 236/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 49544.0742\n",
      "Epoch 237/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 49535.1445\n",
      "Epoch 238/300\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 50118.0000\n",
      "Epoch 239/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 50186.6797\n",
      "Epoch 240/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 50127.7031\n",
      "Epoch 241/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 49796.7578\n",
      "Epoch 242/300\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 49561.8320\n",
      "Epoch 243/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 49603.7070\n",
      "Epoch 244/300\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 49611.8359\n",
      "Epoch 245/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 49577.9180\n",
      "Epoch 246/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 49549.2930\n",
      "Epoch 247/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 49497.3984\n",
      "Epoch 248/300\n",
      "2/2 [==============================] - 0s 1000us/step - loss: 49594.1250\n",
      "Epoch 249/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 49549.5469\n",
      "Epoch 250/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 49516.7930\n",
      "Epoch 251/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 49438.8320\n",
      "Epoch 252/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 49494.4688\n",
      "Epoch 253/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 49510.7812\n",
      "Epoch 254/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 49473.8438\n",
      "Epoch 255/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 49461.3242\n",
      "Epoch 256/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 49525.5664\n",
      "Epoch 257/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 49515.0078\n",
      "Epoch 258/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 49481.7969\n",
      "Epoch 259/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 49426.1602\n",
      "Epoch 260/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 49465.1289\n",
      "Epoch 261/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 49581.2188\n",
      "Epoch 262/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 49578.8945\n",
      "Epoch 263/300\n",
      "2/2 [==============================] - 0s 1000us/step - loss: 49405.4023\n",
      "Epoch 264/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 49418.3828\n",
      "Epoch 265/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 49408.6758\n",
      "Epoch 266/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 49403.4844\n",
      "Epoch 267/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 49648.3516\n",
      "Epoch 268/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 49827.0000\n",
      "Epoch 269/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 49755.8633\n",
      "Epoch 270/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 49953.1914\n",
      "Epoch 271/300\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 49462.9336\n",
      "Epoch 272/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 49552.1680\n",
      "Epoch 273/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 49613.3555\n",
      "Epoch 274/300\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 49790.3828\n",
      "Epoch 275/300\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 49772.6680\n",
      "Epoch 276/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 49647.4766\n",
      "Epoch 277/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 49599.4883\n",
      "Epoch 278/300\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 49802.1133\n",
      "Epoch 279/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 49749.4062\n",
      "Epoch 280/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 49447.0664\n",
      "Epoch 281/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 49426.2812\n",
      "Epoch 282/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 49374.8320\n",
      "Epoch 283/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 49399.3516\n",
      "Epoch 284/300\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 49404.7852\n",
      "Epoch 285/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 49953.8281\n",
      "Epoch 286/300\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 49667.8555\n",
      "Epoch 287/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 49833.1562\n",
      "Epoch 288/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 49867.1016\n",
      "Epoch 289/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 49394.7969\n",
      "Epoch 290/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 49347.5898\n",
      "Epoch 291/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 49383.7305\n",
      "Epoch 292/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 49341.0273\n",
      "Epoch 293/300\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 49332.3398\n",
      "Epoch 294/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 49339.3086\n",
      "Epoch 295/300\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 49783.8672\n",
      "Epoch 296/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 49636.9336\n",
      "Epoch 297/300\n",
      "2/2 [==============================] - 0s 1000us/step - loss: 49661.5117\n",
      "Epoch 298/300\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 49667.2461\n",
      "Epoch 299/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 49527.0312\n",
      "Epoch 300/300\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 49361.3398\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ef33c337f0>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 학습진행 \n",
    "# epoch\n",
    "model.fit(x=train_input, y=train_target, epochs=300, verbose=1)   # 반복 메시지를 안찍음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[16.741928]], dtype=float32), array([-11.508883], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "print(model.get_weights())   ## 앞이 w, 뒤가 b , weight는 1에 가까운값, b는 0에 가까운값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 26ms/step\n",
      "[[825.5875]]\n"
     ]
    }
   ],
   "source": [
    "# 예측\n",
    "print(model.predict([[50]])) # 입력 2차원 배열 \n",
    "# Linear Reggression 끝!!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fe3d9237b4a62cd7715eb234158a07f236d8efc42b8ea743ee7cae33e0917df2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
